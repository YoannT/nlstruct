{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nlstruct.core.environment import env\n",
    "from nlstruct.core.text import transform_text, apply_deltas, encode_as_tag\n",
    "from nlstruct.chunking.spacy_tokenization import spacy_tokenize, SPACY_ATTRIBUTES\n",
    "from nlstruct.core.pandas import normalize_vocabularies\n",
    "from nlstruct.core.cache import get_cache\n",
    "from nlstruct.dataloaders.brat import load_from_brat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "docs, mentions, labels, fragments = load_from_brat(env.resource(\"brat/my_brat_dataset/\"))[[\"docs\", \"mentions\", \"labels\", \"fragments\"]]\n",
    "\n",
    "# Clean the text / perform substitutions\n",
    "subs = [\n",
    "    (re.escape(\"<????-??-??>\"), \"MASKEDDATE\"),\n",
    "    (r\"(?<=[{}\\\\])(?![ ])\".format(string.punctuation), r\" \"),\n",
    "    (r\"(?<![ ])(?=[{}\\\\])\".format(string.punctuation), r\" \"),\n",
    "    (\"(?<=[a-zA-Z])(?=[0-9])\", r\" \"),\n",
    "    (\"(?<=[0-9])(?=[A-Za-z])\", r\" \"),\n",
    "    (\"MASKEDDATE\", \"<????-??-??>\"),\n",
    "]\n",
    "docs, deltas = transform_text.nocache(docs, *zip(*subs), return_deltas=True)\n",
    "\n",
    "# Apply transformations to the spans\n",
    "fragments = apply_deltas(fragments, deltas, on='doc_id')\n",
    "fragments = fragments.merge(mentions)\n",
    "\n",
    "# TOKENIZE\n",
    "tokens = (\n",
    "    spacy_tokenize.nocache(docs, lang=\"fr_core_news_sm\", spacy_attributes=[\"orth_\"])#, spacy_attributes=list((set(SPACY_ATTRIBUTES) - {\"norm_\"}) | {\"lemma_\"}),)\n",
    "    #spm_tokenize.nocache(docs, \"/Users/perceval/Development/data/resources/camembert.v0/sentencepiece.bpe.model\")\n",
    ")\n",
    "tokens[\"token_orth\"] = tokens[\"token_orth\"].apply(lambda word: {\n",
    "    \"$\": \"${dollar}\",\n",
    "    \"_\": \"${underscore}\",\n",
    "    \"\\t\": \"${tab}\",\n",
    "    \"\\n\": \"${newline}\",\n",
    "    \" \": \"${space}\",\n",
    "    \"#\": \"${hash}\"}.get(word, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vocabularies, needed before encode_as_tag since each \"tagified\" label needs to have its category \n",
    "[tokens, fragments], vocabularies = normalize_vocabularies([tokens, fragments])\n",
    "\n",
    "# Encode labels into tag on tokens, with respect to the fragments indices\n",
    "if fragments is not None:\n",
    "    tokens = encode_as_tag(tokens, fragments, tag_scheme=\"bio\", use_token_idx=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = get_cache(\"brat_conll\")\n",
    "for doc_id, doc_tokens in tqdm(tokens.groupby([\"doc_id\"], sort=\"begin\")):\n",
    "    with open(cache / (doc_id + \".conll\"), \"w\") as file:\n",
    "        for token_idx, token, label in doc_tokens[[\"token_idx\", \"token_orth\", \"label\"]].itertuples(index=False): # iter(zip(*df)) is way faster than df.iterrows()\n",
    "            print(token_idx, \"\\t\", token, \"\\t\", label, file=file)\n",
    "for doc_id, doc_text in docs[[\"doc_id\", \"text\"]].itertuples(index=False):\n",
    "    with open(cache / (doc_id + \".txt\"), \"w\") as file:\n",
    "        print(doc_text, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLStruct",
   "language": "python",
   "name": "nlstruct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
